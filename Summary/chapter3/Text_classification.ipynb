{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOimAu4ieJiCmYPVSjoCXAe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## BERT Fine Tuning method for Downstream Tasks."],"metadata":{"id":"AvSwlccaiykB"}},{"cell_type":"markdown","source":["### Text classification"],"metadata":{"id":"RTeXCvtMjJK3"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GEvKp7euicMM","executionInfo":{"status":"ok","timestamp":1700396908320,"user_tz":-540,"elapsed":13336,"user":{"displayName":"정지원","userId":"16823124283758121408"}},"outputId":"e3c7bfa7-29ee-4c5d-ef00-ab82b2f29bca"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting nlp\n","  Downloading nlp-0.4.0-py3-none-any.whl (1.7 MB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.7 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.6/1.7 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from nlp) (1.23.5)\n","Requirement already satisfied: pyarrow>=0.16.0 in /usr/local/lib/python3.10/dist-packages (from nlp) (9.0.0)\n","Collecting dill (from nlp)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from nlp) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from nlp) (2.31.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from nlp) (4.66.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from nlp) (3.13.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from nlp) (3.4.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->nlp) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->nlp) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->nlp) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->nlp) (2023.7.22)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->nlp) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->nlp) (2023.3.post1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->nlp) (1.16.0)\n","Installing collected packages: dill, nlp\n","Successfully installed dill-0.3.7 nlp-0.4.0\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"]}],"source":["!pip install nlp\n","!pip install transformers"]},{"cell_type":"code","source":["from transformers import BertForSequenceClassification, BertTokenizerFast, Trainer,TrainingArguments\n","from nlp import load_dataset\n","import torch\n","import numpy as np"],"metadata":{"id":"Ke8H79rDjYWp","executionInfo":{"status":"ok","timestamp":1700398075231,"user_tz":-540,"elapsed":7985,"user":{"displayName":"정지원","userId":"16823124283758121408"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["!gdown https://drive.google.com/uc?id=11_M4ootuT7I1G0RlihcC0cA3Elqotlc-\n","dataset = load_dataset('csv', data_files='./imdbs.csv', split='train')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QZcOUTnYjtr2","executionInfo":{"status":"ok","timestamp":1700398078968,"user_tz":-540,"elapsed":3740,"user":{"displayName":"정지원","userId":"16823124283758121408"}},"outputId":"8e3a970b-7abd-404f-9648-7f5b2bc93e0d"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=11_M4ootuT7I1G0RlihcC0cA3Elqotlc-\n","To: /content/imdbs.csv\n","\r  0% 0.00/132k [00:00<?, ?B/s]\r100% 132k/132k [00:00<00:00, 88.3MB/s]\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:nlp.builder:Using custom data configuration default\n"]}]},{"cell_type":"code","source":["type(dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gnH3teNbjwU2","executionInfo":{"status":"ok","timestamp":1700398078968,"user_tz":-540,"elapsed":3,"user":{"displayName":"정지원","userId":"16823124283758121408"}},"outputId":"5d461ddb-a5a2-4f43-95da-f805fd6ff610"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["nlp.arrow_dataset.Dataset"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["dataset = dataset.train_test_split(test_size=0.2)"],"metadata":{"id":"fWcJfrpTj-ae","executionInfo":{"status":"ok","timestamp":1700398078968,"user_tz":-540,"elapsed":2,"user":{"displayName":"정지원","userId":"16823124283758121408"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8FpIiTx6kCev","executionInfo":{"status":"ok","timestamp":1700398078968,"user_tz":-540,"elapsed":2,"user":{"displayName":"정지원","userId":"16823124283758121408"}},"outputId":"bc43d947-a8cd-46d6-ccf3-ff020238696e"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'train': Dataset(features: {'text': Value(dtype='string', id=None), 'label': Value(dtype='int64', id=None)}, num_rows: 80),\n"," 'test': Dataset(features: {'text': Value(dtype='string', id=None), 'label': Value(dtype='int64', id=None)}, num_rows: 20)}"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["train_set = dataset['train']\n","test_set = dataset['test']"],"metadata":{"id":"IubBudBakD3T","executionInfo":{"status":"ok","timestamp":1700398078969,"user_tz":-540,"elapsed":2,"user":{"displayName":"정지원","userId":"16823124283758121408"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["model = BertForSequenceClassification.from_pretrained('bert-base-uncased')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X5IzwE8okXiW","executionInfo":{"status":"ok","timestamp":1700398082989,"user_tz":-540,"elapsed":4022,"user":{"displayName":"정지원","userId":"16823124283758121408"}},"outputId":"3ca891ff-2473-4fef-d36e-32fb36139c78"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"],"metadata":{"id":"fUSMHcJlki7p","executionInfo":{"status":"ok","timestamp":1700398082990,"user_tz":-540,"elapsed":6,"user":{"displayName":"정지원","userId":"16823124283758121408"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["#### Preprocess the dataset\n","\n","we can preprocess the dataset in a quicker way using our tokenizer. For example, consider the sentence: 'I love Paris'.\n","\n","First, we tokenize the sentence and add the [CLS] token at the beginning and [SEP] token at the end as shown below:\n","\n","tokens = [ [CLS], I, love, Paris, [SEP] ]\n","\n","Next, we map the tokens to the unique input ids (token ids). Suppose the following are the unique input ids (token ids):\n","\n","input_ids = [101, 1045, 2293, 3000, 102]\n","\n","Then, we need to add the segment ids (token type ids). Wait, what are segment ids? Suppose we have two sentences in the input. In that case, segment ids are used to distinguish one sentence from the other. All the tokens from the first sentence will be mapped to 0 and all the tokens from the second sentence will be mapped to 1. Since here we have only one sentence, all the tokens will be mapped to 0 as shown below:\n","\n","token_type_ids = [0, 0, 0, 0, 0]\n","\n","Now, we need to create the attention mask. We know that an attention mask is used to differentiate the actual tokens and [PAD] tokens. It will map all the actual tokens to 1 and the [PAD] tokens to 0. Suppose, our tokens length should be 5. Now, our tokens list has already 5 tokens. So, we don't have to add [PAD] token. Then our attention mask will become:\n","\n","attention_mask = [1, 1, 1, 1, 1]\n","\n","That's it. But instead of doing all the above steps manually, our tokenizer will do these steps for us. We just need to pass the sentence to the tokenizer as shown below:"],"metadata":{"id":"P4m0A7T2ksyX"}},{"cell_type":"code","source":["tokenizer('I love Seoul')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"11CwGAQHknHD","executionInfo":{"status":"ok","timestamp":1700398082990,"user_tz":-540,"elapsed":5,"user":{"displayName":"정지원","userId":"16823124283758121408"}},"outputId":"55115773-c91b-4bfb-a5b3-608908dab9af"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': [101, 1045, 2293, 10884, 102], 'token_type_ids': [0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1]}"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["tokenizer(['I love Paris', 'birds fly','snow fall'], padding = True, max_length=5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ED7_gBSUlKbR","executionInfo":{"status":"ok","timestamp":1700398082990,"user_tz":-540,"elapsed":5,"user":{"displayName":"정지원","userId":"16823124283758121408"}},"outputId":"ec12bf0a-9d65-4384-b0f5-b78cebb7f723"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2632: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["{'input_ids': [[101, 1045, 2293, 3000, 102], [101, 5055, 4875, 102, 0], [101, 4586, 2991, 102, 0]], 'token_type_ids': [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1], [1, 1, 1, 1, 0], [1, 1, 1, 1, 0]]}"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["That's it, with the tokenizer, we can easily preprocess our dataset. So we define a function called preprocess for processing the dataset as shown below :"],"metadata":{"id":"gOWKWy6-lOgl"}},{"cell_type":"code","source":["def preprocess(data):\n","    return tokenizer(data['text'],padding=True,truncation=True)"],"metadata":{"id":"YqYmwR1plM4P","executionInfo":{"status":"ok","timestamp":1700398082990,"user_tz":-540,"elapsed":3,"user":{"displayName":"정지원","userId":"16823124283758121408"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["Now, we preprocess the train and test set using the preprocess function:"],"metadata":{"id":"seYAi90rler_"}},{"cell_type":"code","source":["!pip uninstall dill\n","!pip install dill==0.2.8.2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":479},"id":"-Jtvs9yOmHRn","executionInfo":{"status":"ok","timestamp":1700397638236,"user_tz":-540,"elapsed":14010,"user":{"displayName":"정지원","userId":"16823124283758121408"}},"outputId":"70296ed3-2399-4f67-edb4-251b091e0f75"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: dill 0.3.7\n","Uninstalling dill-0.3.7:\n","  Would remove:\n","    /usr/local/bin/get_gprof\n","    /usr/local/bin/get_objgraph\n","    /usr/local/bin/undill\n","    /usr/local/lib/python3.10/dist-packages/dill-0.3.7.dist-info/*\n","    /usr/local/lib/python3.10/dist-packages/dill/*\n","Proceed (Y/n)? y\n","  Successfully uninstalled dill-0.3.7\n","Collecting dill==0.2.8.2\n","  Downloading dill-0.2.8.2.tar.gz (150 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: dill\n","  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for dill: filename=dill-0.2.8.2-py3-none-any.whl size=76466 sha256=a7a91cf7b28f3a219590f5ae63ea7bc9c414c38339abc032febd4fa25caf5d80\n","  Stored in directory: /root/.cache/pip/wheels/41/7b/c2/449a7de961d41b03ff714fd80b35603435776c08ebce576ab1\n","Successfully built dill\n","Installing collected packages: dill\n","Successfully installed dill-0.2.8.2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["dill"]}}},"metadata":{}}]},{"cell_type":"code","source":["train_set = train_set.map(preprocess, batched=True, batch_size=len(train_set))\n","test_set = test_set.map(preprocess, batched=True, batch_size=len(test_set))\n"],"metadata":{"id":"Dx-gl-9qlb6L","executionInfo":{"status":"ok","timestamp":1700398083707,"user_tz":-540,"elapsed":2,"user":{"displayName":"정지원","userId":"16823124283758121408"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["Next, we use the set_format function and select the columns which we need in our dataset and also in which format we need them as shown below:"],"metadata":{"id":"kHVlMTgBmtmE"}},{"cell_type":"code","source":["train_set.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n","test_set.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])"],"metadata":{"id":"R4zfbmd1l2iy","executionInfo":{"status":"ok","timestamp":1700398083708,"user_tz":-540,"elapsed":2,"user":{"displayName":"정지원","userId":"16823124283758121408"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["#### Training the model"],"metadata":{"id":"DFKbPfdwm7YH"}},{"cell_type":"code","source":["batch_size=8\n","epochs=2\n","warmup_steps=500\n","weight_decay=0.01"],"metadata":{"id":"e5FJOATJm6rX","executionInfo":{"status":"ok","timestamp":1700398083708,"user_tz":-540,"elapsed":2,"user":{"displayName":"정지원","userId":"16823124283758121408"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["!pip install accelerate -U"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kKQCzAA1nPFD","executionInfo":{"status":"ok","timestamp":1700397920785,"user_tz":-540,"elapsed":14172,"user":{"displayName":"정지원","userId":"16823124283758121408"}},"outputId":"3de1081c-c4a3-4909-b785-a3dc1d6af720"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting accelerate\n","  Downloading accelerate-0.24.1-py3-none-any.whl (261 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/261.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/261.4 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m256.0/261.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu118)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.19.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Installing collected packages: accelerate\n","Successfully installed accelerate-0.24.1\n"]}]},{"cell_type":"code","source":["training_args = TrainingArguments(\n","    output_dir='./results',\n","    num_train_epochs=epochs,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    warmup_steps=warmup_steps,\n","    weight_decay=weight_decay,\n","    logging_dir='./logs',\n",")"],"metadata":{"id":"uWKgf4LrnBD7","executionInfo":{"status":"ok","timestamp":1700398222828,"user_tz":-540,"elapsed":889,"user":{"displayName":"정지원","userId":"16823124283758121408"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_set,\n","    eval_dataset=test_set\n",")\n"],"metadata":{"id":"Yr6HvoylnFvc","executionInfo":{"status":"ok","timestamp":1700398238154,"user_tz":-540,"elapsed":7339,"user":{"displayName":"정지원","userId":"16823124283758121408"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":110},"id":"eokxF6ProegD","executionInfo":{"status":"ok","timestamp":1700398258691,"user_tz":-540,"elapsed":17636,"user":{"displayName":"정지원","userId":"16823124283758121408"}},"outputId":"f53d0c83-cf36-445b-e4c3-7e4bd80e5790"},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [20/20 00:13, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=20, training_loss=0.6922211170196533, metrics={'train_runtime': 17.2659, 'train_samples_per_second': 9.267, 'train_steps_per_second': 1.158, 'total_flos': 42097768857600.0, 'train_loss': 0.6922211170196533, 'epoch': 2.0})"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["trainer.evaluate()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":124},"id":"Ed8YTFzfohCd","executionInfo":{"status":"ok","timestamp":1700398263906,"user_tz":-540,"elapsed":620,"user":{"displayName":"정지원","userId":"16823124283758121408"}},"outputId":"ee497ecc-9577-44e5-bc48-3f4f48d53c3c"},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3/3 00:00]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'eval_loss': 0.7181774377822876,\n"," 'eval_runtime': 0.6873,\n"," 'eval_samples_per_second': 29.098,\n"," 'eval_steps_per_second': 4.365,\n"," 'epoch': 2.0}"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["In this way, we can finetune the pre-trained BERT. Now that we have learned how to finetune the BERT for the text classification task."],"metadata":{"id":"MW3OCyTvonmt"}},{"cell_type":"markdown","source":["### Q&A with finetuned BERT\n","\n","In this section, let's learn how to perform question answering with a finetuned Q&A BERT. First, let us import the necessary modules:"],"metadata":{"id":"REmAnG85pGfH"}},{"cell_type":"code","source":["import torch\n","from transformers import BertForQuestionAnswering, BertTokenizer"],"metadata":{"id":"KK5Cq6AAomeZ","executionInfo":{"status":"ok","timestamp":1700399159643,"user_tz":-540,"elapsed":4,"user":{"displayName":"정지원","userId":"16823124283758121408"}}},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":["Now, we download and load the model. We use the bert-large-uncased-whole-word-masking-finetuned-squad model which is finetuned on the SQUAD (Stanford question answering dataset)."],"metadata":{"id":"MN7slUcpqGra"}},{"cell_type":"code","source":["model_qa = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iNRWv57XpSEQ","executionInfo":{"status":"ok","timestamp":1700399167606,"user_tz":-540,"elapsed":6487,"user":{"displayName":"정지원","userId":"16823124283758121408"}},"outputId":"4673f802-0633-416b-811e-603af0100d4b"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n","- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","source":["tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n"],"metadata":{"id":"NFgTaiEUqIdu","executionInfo":{"status":"ok","timestamp":1700399169379,"user_tz":-540,"elapsed":457,"user":{"displayName":"정지원","userId":"16823124283758121408"}}},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":["#### Preprocessing the input\n","\n","First, we define the input to BERT which is question and paragraph text:"],"metadata":{"id":"-qe-x6HpqKgz"}},{"cell_type":"code","source":["question = \"What is the immune system?\"\n","paragraph = \"The immune system is a system of many biological structures and processes within an organism that protects against disease. To function properly, an immune system must detect a wide variety of agents, known as pathogens, from viruses to parasitic worms, and distinguish them from the organism's own healthy tissue.\""],"metadata":{"id":"03TuTbbxqJpD","executionInfo":{"status":"ok","timestamp":1700399173338,"user_tz":-540,"elapsed":2,"user":{"displayName":"정지원","userId":"16823124283758121408"}}},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":["Add [CLS] token to the beginning of the question and [SEP] token at the end of both the question and paragraph:"],"metadata":{"id":"gISG5rnFqgnU"}},{"cell_type":"code","source":["question = '[CLS]' + question + '[SEP]'\n","paragraph += '[SEP]'"],"metadata":{"id":"fInZIOdWqfm0","executionInfo":{"status":"ok","timestamp":1700399174145,"user_tz":-540,"elapsed":2,"user":{"displayName":"정지원","userId":"16823124283758121408"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["question_tokens = tokenizer.tokenize(question)\n","paragraph_tokens = tokenizer.tokenize(paragraph)"],"metadata":{"id":"ZyYJju0Lqtva","executionInfo":{"status":"ok","timestamp":1700399174145,"user_tz":-540,"elapsed":1,"user":{"displayName":"정지원","userId":"16823124283758121408"}}},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":["Combine the question and paragraph tokens and convert them to input_ids:"],"metadata":{"id":"MD5onYTZq02Y"}},{"cell_type":"code","source":["tokens = question_tokens + paragraph_tokens\n","input_ids = tokenizer.convert_tokens_to_ids(tokens)"],"metadata":{"id":"114s2-2PqzNB","executionInfo":{"status":"ok","timestamp":1700399174687,"user_tz":-540,"elapsed":2,"user":{"displayName":"정지원","userId":"16823124283758121408"}}},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":["Next, we define the segment_ids. The segment_ids will be 0 for all the tokens of question and it will be 1 for all the tokens of the paragraph:"],"metadata":{"id":"jjjpoxpbrAnl"}},{"cell_type":"code","source":["segment_ids = [0] * len(question_tokens)\n","segment_ids += [1] * len(paragraph_tokens)"],"metadata":{"id":"4JPleBCdq8vU","executionInfo":{"status":"ok","timestamp":1700399178339,"user_tz":-540,"elapsed":1,"user":{"displayName":"정지원","userId":"16823124283758121408"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["input_ids = torch.tensor([input_ids])\n","segment_ids = torch.tensor([segment_ids])\n","print(input_ids)\n","print(segment_ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5HEqmduTq8Xq","executionInfo":{"status":"ok","timestamp":1700399178963,"user_tz":-540,"elapsed":2,"user":{"displayName":"정지원","userId":"16823124283758121408"}},"outputId":"33a89065-898b-4374-8641-c104135e1d63"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[  101,  2054,  2003,  1996, 11311,  2291,  1029,   102,  1996, 11311,\n","          2291,  2003,  1037,  2291,  1997,  2116,  6897,  5090,  1998,  6194,\n","          2306,  2019, 15923,  2008, 18227,  2114,  4295,  1012,  2000,  3853,\n","          7919,  1010,  2019, 11311,  2291,  2442, 11487,  1037,  2898,  3528,\n","          1997,  6074,  1010,  2124,  2004, 26835,  2015,  1010,  2013, 18191,\n","          2000, 26045, 16253,  1010,  1998, 10782,  2068,  2013,  1996, 15923,\n","          1005,  1055,  2219,  7965,  8153,  1012,   102]])\n","tensor([[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"]}]},{"cell_type":"markdown","source":["#### Getting the answer\n","\n","we feed the input_ids and segment_ids to the model which return the start score and end score for all of the tokens:"],"metadata":{"id":"EuZUyXenrckV"}},{"cell_type":"code","source":["result=model_qa(input_ids, token_type_ids = segment_ids)"],"metadata":{"id":"WXVJJNhJrVIm","executionInfo":{"status":"ok","timestamp":1700399210742,"user_tz":-540,"elapsed":2298,"user":{"displayName":"정지원","userId":"16823124283758121408"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["model_qa"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yB9HdMzZtBz0","executionInfo":{"status":"ok","timestamp":1700399433106,"user_tz":-540,"elapsed":4,"user":{"displayName":"정지원","userId":"16823124283758121408"}},"outputId":"3b7b5319-2962-43d6-eaa0-fb9a1bc655d2"},"execution_count":63,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertForQuestionAnswering(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n","      (position_embeddings): Embedding(512, 1024)\n","      (token_type_embeddings): Embedding(2, 1024)\n","      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-23): 24 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (qa_outputs): Linear(in_features=1024, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":63}]},{"cell_type":"code","source":["print(input_ids.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SUd2ZwQfsV8Q","executionInfo":{"status":"ok","timestamp":1700399264269,"user_tz":-540,"elapsed":628,"user":{"displayName":"정지원","userId":"16823124283758121408"}},"outputId":"068927fd-19cb-447b-fe71-c9e18423add2"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 67])\n"]}]},{"cell_type":"code","source":["print(result.keys())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZxxPeg6dsONM","executionInfo":{"status":"ok","timestamp":1700399221111,"user_tz":-540,"elapsed":4,"user":{"displayName":"정지원","userId":"16823124283758121408"}},"outputId":"6d4db0e5-1aa6-4b48-e4c0-485b843c6799"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["odict_keys(['start_logits', 'end_logits'])\n"]}]},{"cell_type":"code","source":["print(result[0].shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zq5CTmfzsS-6","executionInfo":{"status":"ok","timestamp":1700399238145,"user_tz":-540,"elapsed":4,"user":{"displayName":"정지원","userId":"16823124283758121408"}},"outputId":"ff29d949-a65c-4ab5-e4c4-37cd7ca77827"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 67])\n"]}]},{"cell_type":"code","source":["print(result[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M4yxildftRQY","executionInfo":{"status":"ok","timestamp":1700399492082,"user_tz":-540,"elapsed":3,"user":{"displayName":"정지원","userId":"16823124283758121408"}},"outputId":"75ddb714-dd3f-4f39-93be-c4dbbc4b0992"},"execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[-6.2588, -4.6880, -6.7744, -6.3712, -5.8096, -8.4909, -9.0369, -6.2588,\n","          2.3760, -0.8670, -4.0859,  2.1112,  7.0353,  3.1633, -2.0016,  1.8844,\n","          2.4239, -0.8321, -4.7245, -0.6628, -0.9607, -1.5406, -0.9789, -1.5246,\n","          1.5805, -3.6135, -1.7062, -6.2587, -4.3460, -5.7781, -6.2772, -7.2236,\n","         -2.5216, -2.8306, -5.5702, -4.4567, -3.9796, -6.1513, -5.8940, -6.4212,\n","         -7.3876, -5.6694, -7.7685, -4.6375, -6.5613, -3.7148, -7.0651, -8.1083,\n","         -5.4551, -4.3829, -7.9004, -4.8883, -5.8361, -7.9597, -6.8583, -4.6028,\n","         -7.3392, -7.3848, -6.5887, -5.8965, -5.8692, -7.9263, -6.7758, -5.4052,\n","         -5.2147, -7.6892, -6.2588]], grad_fn=<CloneBackward0>)\n"]}]},{"cell_type":"code","source":["start_index = torch.argmax(result[0])\n","end_index = torch.argmax(result[1])"],"metadata":{"id":"n2xuB1fprrwB","executionInfo":{"status":"ok","timestamp":1700399281531,"user_tz":-540,"elapsed":472,"user":{"displayName":"정지원","userId":"16823124283758121408"}}},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":["Now, we print the text span between the start and end index as our answer:"],"metadata":{"id":"OyMj-r7YskAF"}},{"cell_type":"code","source":["print(' '.join(tokens[start_index:end_index+1]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x-nDFPVXrvTp","executionInfo":{"status":"ok","timestamp":1700399318625,"user_tz":-540,"elapsed":4,"user":{"displayName":"정지원","userId":"16823124283758121408"}},"outputId":"bf7339ae-7f61-4dd9-e4ae-1ffc223f665a"},"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["a system of many biological structures and processes within an organism that protects against disease\n"]}]},{"cell_type":"markdown","source":["정리하자면, 데이터 셋을 가지고 허깅페이스에서 모델을 불러와서 학습을 시키는 과정은 fine-tuning, 불러온 모델에 나의 데이터셋을 그냥 넣어보는것은 feature extractor라고 볼 수 있다."],"metadata":{"id":"kjKAoJGAufH_"}},{"cell_type":"code","source":[],"metadata":{"id":"vMbTApoRsoKv"},"execution_count":null,"outputs":[]}]}